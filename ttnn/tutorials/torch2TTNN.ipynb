{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d326abce-ada9-4a70-8297-035122d654a2",
   "metadata": {},
   "source": [
    "# Torch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0031a1-b83d-4373-9859-48d07dfd3d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From transformers.models.bert.modeling_bert.BertIntermediate\n",
    "# https://github.com/huggingface/transformers/blob/main/src/transformers/models/bert/modeling_bert.py or https://huggingface.co/transformers/v2.5.0/_modules/transformers/modeling_bert.html (find BertIntermidiate here, we have modified it a bit here)\n",
    "\n",
    "import torch\n",
    "\n",
    "class BertIntermediate(torch.nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = torch.nn.Linear(config.hidden_size, config.intermediate_size)\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = torch.nn.functional.gelu(hidden_states)\n",
    "        return hidden_states\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcfeb90-7cfa-4579-a505-7050ba36ded5",
   "metadata": {},
   "source": [
    "# And finally, the model can be rewritten using functional torch APIs to make the test pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce6f467-62f5-474d-9873-91f1da60b2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch_functional_bert.py\n",
    "\n",
    "def bert_intermediate(hidden_states, *, parameters):\n",
    "    hidden_states = hidden_states @ parameters.dense.weight\n",
    "    hidden_states = hidden_states + parameters.dense.bias\n",
    "    hidden_states = torch.nn.functional.gelu(hidden_states)\n",
    "    return hidden_states\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e8e200b8-ad6d-49f3-aef7-ee12fcb5ca54",
   "metadata": {},
   "source": [
    "parameters is a dictionary which sets its keys as its attributes, so both parameters[\"dense\"][\"weight\"] and parameters.dense.weight are valid.\n",
    "\n",
    "The structure of parameters follows the structure of the model class. In this case, BertIntermediate has a single attribute dense, so parameters has a single attribute dense. And dense is a torch.nn.Linear object, so it in turn has two attributes weight and bias.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259780f2-c280-4c4b-8feb-6c0650376c14",
   "metadata": {},
   "source": [
    "# Following TDD, the first step is to write a test for the model:\n",
    "# What is TDD? Need to add acrynoms docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed8f093-4549-4ca7-b3d1-846224d15f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_intermediate(hidden_states, *, parameters):\n",
    "    hidden_states = hidden_states @ parameters.dense.weight\n",
    "    hidden_states = hidden_states + parameters.dense.bias\n",
    "    hidden_states = torch.nn.functional.gelu(hidden_states)\n",
    "    return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecf2194a-63a7-46d0-9ff8-9927bdb64467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "import ttnn\n",
    "import sys\n",
    "#import os\n",
    "#current_path = os.getcwd()\n",
    "#print(\"the current path is: \", current_path)\n",
    "sys.path.append(\"/home/dvartanians/tt-metal-v0.41.0/tt-metal/models/experimental/functional_bert/reference\")\n",
    "import torch_functional_bert # implemented here: https://github.com/tenstorrent-metal/tt-metal/blob/main/models/experimental/functional_bert/reference/torch_functional_bert.py\n",
    "\n",
    "from models.utility_functions import torch_random\n",
    "from tests.ttnn.utils_for_testing import assert_with_pcc\n",
    "\n",
    "@pytest.mark.parametrize(\"model_name\", [\"phiyodr/bert-large-finetuned-squad2\"])\n",
    "@pytest.mark.parametrize(\"batch_size\", [1])\n",
    "@pytest.mark.parametrize(\"sequence_size\", [384])\n",
    "def test_bert_intermediate(model_name, batch_size, sequence_size):\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    config = transformers.BertConfig.from_pretrained(model_name)\n",
    "    model = transformers.models.bert.modeling_bert.BertIntermediate(config).eval()\n",
    "\n",
    "    torch_hidden_states = torch_random((batch_size, sequence_size, config.hidden_size), -0.1, 0.1, dtype=torch.float32)\n",
    "    torch_output = model(torch_hidden_states) # Golden output\n",
    "\n",
    "\n",
    "    # where is this function defined? \n",
    "    # must be the following:\n",
    "    from ttnn.model_preprocessing import preprocess_model_parameters\n",
    "    parameters = preprocess_model_parameters(\n",
    "        initialize_model=lambda: model, # Function to initialize the model\n",
    "        convert_to_ttnn=lambda *_: False, # Keep the weights as torch tensors\n",
    "    )\n",
    "\n",
    "    output = torch_functional_bert.bert_intermediate(\n",
    "        torch_hidden_states,\n",
    "        parameters=parameters,\n",
    "    )\n",
    "    #output = bert_intermediate(\n",
    "    #    torch_hidden_states,\n",
    "    #    parameters=parameters,\n",
    "    #)\n",
    "\n",
    "    \n",
    "    assert_with_pcc(torch_output, output, 0.9999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8336a6-8318-4dd7-81c3-265af73f5198",
   "metadata": {},
   "source": [
    "# Step 2 - Switching to ttnn ops"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c677c4f8-4775-47cb-8849-7349c83c1c6c",
   "metadata": {},
   "source": [
    "Starting off with the test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67505cf6-e5f7-4af0-bd7a-34a545ce9582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "import ttnn\n",
    "#import ttnn_functional_bert\n",
    "\n",
    "from models.utility_functions import torch_random\n",
    "from tests.ttnn.utils_for_testing import assert_with_pcc\n",
    "\n",
    "@pytest.mark.parametrize(\"model_name\", [\"phiyodr/bert-large-finetuned-squad2\"])\n",
    "@pytest.mark.parametrize(\"batch_size\", [1])\n",
    "@pytest.mark.parametrize(\"sequence_size\", [384])\n",
    "def test_bert_intermediate(device, model_name, batch_size, sequence_size):\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    config = transformers.BertConfig.from_pretrained(model_name)\n",
    "    model = transformers.models.bert.modeling_bert.BertIntermediate(config).eval()\n",
    "\n",
    "    torch_hidden_states = torch_random((batch_size, sequence_size, config.hidden_size), -0.1, 0.1)\n",
    "    torch_output = model(torch_hidden_states)\n",
    "\n",
    "    parameters = preprocess_model_parameters(\n",
    "        initialize_model=lambda: model.to(torch.bfloat16),\n",
    "        device=device, # Device to put the parameters on\n",
    "    )\n",
    "\n",
    "    hidden_states = ttnn.from_torch(torch_hidden_states, dtype=ttnn.bfloat16)\n",
    "    hidden_states = ttnn.to_layout(hidden_states, ttnn.TILE_LAYOUT)\n",
    "    hidden_states = ttnn.to_device(hidden_states, device)\n",
    "    #output = ttnn_functional_bert.bert_intermediate(\n",
    "    #    hidden_states,\n",
    "    #    parameters=parameters,\n",
    "    #)\n",
    "\n",
    "    output = bert_intermediate(\n",
    "        hidden_states,\n",
    "        parameters=parameters,\n",
    "    )\n",
    "    output = ttnn.from_device(output)\n",
    "    output = ttnn.to_layout(output, ttnn.ROW_MAJOR_LAYOUT)\n",
    "    output = ttnn.to_torch(output)\n",
    "\n",
    "    assert_with_pcc(torch_output, output.to(torch_output.dtype), 0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33969f07-3d8b-4517-8b94-1ba0fb08d8a0",
   "metadata": {},
   "source": [
    "# Then implementing the function using ttnn operations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524d47fe-7ce8-4f4f-b721-270b690bd40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ttnn_functional_bert.py\n",
    "\n",
    "import ttnn\n",
    "\n",
    "def bert_intermediate(\n",
    "    hidden_states,\n",
    "    *,\n",
    "    parameters,\n",
    "):\n",
    "    output = hidden_states @ parameters.dense.weight\n",
    "    output = output + parameters.dense.bias\n",
    "    output = ttnn.gelu(output)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413a943f-7225-4f56-92b3-340b3d696e36",
   "metadata": {},
   "source": [
    "# Step 3 - Optimizing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb9a541-db8f-4673-bb12-315ba4e9b043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ttnn_optimized_functional_bert.py\n",
    "\n",
    "import ttnn\n",
    "\n",
    "def bert_intermediate(\n",
    "    hidden_states,\n",
    "    *,\n",
    "    parameters,\n",
    "    num_cores_x,\n",
    "):\n",
    "    batch_size, *_ = hidden_states.shape\n",
    "\n",
    "    num_cores_x = 12\n",
    "    output = ttnn.linear(\n",
    "        hidden_states,\n",
    "        ff1_weight,\n",
    "        bias=ff1_bias,\n",
    "        memory_config=ttnn.L1_MEMORY_CONFIG, # Put the output into local core memory\n",
    "        core_grid=(batch_size, num_cores_x), # Specify manual core grid to get the best possible performance\n",
    "        activation=\"gelu\", # Fuse Gelu\n",
    "    )\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b117cdec-2851-4d95-8f90-ccc21df57aeb",
   "metadata": {},
   "source": [
    "# More examples"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c6b41619-b01b-4b1b-b5b7-8738d482a233",
   "metadata": {},
   "source": [
    "Additional examples can be found in:\n",
    "/tests/ttnn/integration_tests/bert/\n",
    "\n",
    "tests/ttnn/integration_tests/bloom/\n",
    "\n",
    "tests/ttnn/integration_tests/t5/\n",
    "\n",
    "tests/ttnn/integration_tests/whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39d6593-f79f-44e0-b436-b9d032b123f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
